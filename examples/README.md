# DNA Transport GNN Examples

This directory contains examples demonstrating how to use the DNA Transport GNN model.

## Files

- `basic_usage.py` - Basic examples showing graph creation and model usage
- `training_example.py` - Comprehensive training example with synthetic data

## How the Model Works Without Training

### Initial Weights
When you create a `DNATransportGNN` model, PyTorch automatically initializes all weights randomly:

- **Linear layers**: Xavier/Glorot initialization (weights ~ N(0, 2/(in_features + out_features)))
- **GATConv layers**: Kaiming initialization (weights ~ N(0, 2/fan_in))
- **LayerNorm**: Standard normal distribution (weights ~ N(0, 1))

### Why It Can Run Without Training
1. **Mathematical Validity**: All operations (matrix multiplications, activations, pooling) are mathematically valid with random weights
2. **Forward Pass**: The model can perform forward passes and produce outputs
3. **Random Predictions**: Without training, the outputs are essentially random and have no meaningful relationship to the input DNA sequences
4. **Training Purpose**: Training adjusts these random weights to minimize prediction error on labeled data

### Example Output from Untrained Model
```python
# Untrained model produces random predictions
DOS range: [-2.345, 1.876]  # Random values
Transmission range: [0.123, 0.987]  # Random values between 0-1
```

## Training Process

### 1. Data Generation
The training example uses synthetic data generated by `data_generator.py`:
- Random DNA sequences (A, T, G, C)
- Synthetic DOS (Density of States) curves
- Synthetic transmission curves
- Energy grid from -3 to +3 eV

### 2. Graph Construction
Each DNA sequence is converted to a graph:
- Nodes: DNA bases + contact nodes
- Edges: Backbone connections + contact connections
- Features: Base encoding + coupling strengths

### 3. Model Training
- **Loss Function**: MSE for both DOS and transmission predictions
- **Optimizer**: Adam with learning rate 1e-3
- **Training**: 50-100 epochs with train/validation split
- **Evaluation**: R² score and MSE on test set

### 4. Expected Results
After training, the model should:
- Show decreasing loss curves
- Achieve R² > 0.5 on test set
- Produce predictions that correlate with input sequences
- Show meaningful DOS peaks and transmission gaps

## Running the Examples

### Basic Usage
```bash
python examples/basic_usage.py
```

### Training Example
```bash
python examples/training_example.py
```

This will:
1. Generate synthetic training data
2. Train the model for 100 epochs
3. Evaluate performance on test set
4. Save training curves plot
5. Save trained model weights

## Model Architecture

The `DNATransportGNN` consists of:

1. **Input Projections**: Linear layers for node and edge features
2. **Graph Attention Layers**: GATConv layers with multi-head attention
3. **Layer Normalization**: After each GAT layer
4. **Global Pooling**: Mean pooling across all nodes
5. **Output Projections**: Separate heads for DOS and transmission prediction

## Key Parameters

- `node_features`: 8 (base encoding + contact features)
- `edge_features`: 4 (coupling strength + edge type + hydrogen bond flag + directionality)
- `hidden_dim`: 64-128 (hidden representation size)
- `num_layers`: 3-4 (number of GAT layers)
- `output_dim`: 50-100 (number of energy points)

## Training Tips

1. **Data Quality**: Ensure synthetic data follows realistic patterns
2. **Model Size**: Start with smaller models and scale up
3. **Regularization**: Use dropout to prevent overfitting
4. **Learning Rate**: Start with 1e-3 and reduce if needed
5. **Early Stopping**: Monitor validation loss to prevent overfitting

## Expected Performance

With synthetic data, you should see:
- Training loss: ~0.1-0.5
- Validation loss: ~0.1-0.5
- Test R²: ~0.3-0.7 (depending on data complexity)
- Training time: 5-30 minutes on CPU, 1-5 minutes on GPU